---
title: シェーダを動かすパイプライン
date: "2025-04-20"
description: レンダーパイプラインで三角形を表示する
series: webgpu-concept
references:
  - title: WebGPU入門 - WebGPUで三角形を表示する
    url: https://zenn.dev/emadurandal/books/cb6818fd3a1b2e/viewer/hello_triangle
  - title: WebGPU Fundamentals
    url: https://webgpufundamentals.org/webgpu/lessons/webgpu-fundamentals.html
tags:
  - webgpu
draft: true
---

import DemoLinkWithResult from "$/components/demo/DemoLinkWithResult.astro"

import img_WebGpuTriangleNoBuffer from "../../../assets/recipes/webgpu-concept/webgpu-triangle-no-buffer.png"

> [!note]
> ここで学ぶこと
>
> - レンダーパイプライン
> - シェーダのコンパイル
> - レンダーパイプラインレイアウト
> - フラグメントシェーダ出力の`@location(0)`の意味

:SeriesPrevLink[前回]{series="webgpu-concept" current="webgpu-triangle-pipeline"}は、三角形の描画に必要なシェーダを実装しました。

今回は、そのシェーダを使って、実際に三角形を表示するためのWebGPUのコードを実装します。

## シェーダをWebGPUに渡す

シェーダを動かすには、シェーダのコード（WGSLコード）をGPUが理解できる形式に変換してから、GPUに渡す必要があります。
WGSLコードをGPUが理解できる形式に変換する作業を==コンパイル==といいます。

WGSLコードのコンパイルは、WebGPU内部で行ってくれますが、そのためにはWGSLコードを=p=WebGPUに登録==する必要があります。

### シェーダモジュールの作成

WGSLコードをJavaScriptからWebGPUに渡すときに使うのが、`device.createShaderModule{:js}`メソッドです。

このメソッドにWGSLコードを文字列として渡すことで、==シェーダモジュール==（`GPUShaderModule{:ts}`）というオブジェクトが作られます。
単なる文字列だったWGSLコードを、描画処理を構成する1つの部品（モジュール）としてWebGPUが使えるようにしたものが、==シェーダモジュール==です。

実際に、前回実装したWGSLコードを文字列として渡して、シェーダモジュールを作成するコードは次のようになります。

```ts
const shaderModule = device.createShaderModule({
  code: `
    struct VertexInput {
      @builtin(vertex_index) VertexIndex: u32
    };

    struct VertexOutput {
      @builtin(position) Position: vec4f
    };

    @vertex
    fn vs_main(in: VertexInput) -> VertexOutput {
      var pos = array<vec2f, 3>(
        vec2f( 0.0,  0.5),
        vec2f(-0.5, -0.5),
        vec2f( 0.5, -0.5)
      );
    
      var out: VertexOutput;
      out.Position = vec4f(pos[in.VertexIndex], 0.0, 1.0);
      return out;
    }

    @fragment
    fn fs_main() -> @location(0) vec4f {
      return vec4f(0.918, 0.561, 0.918, 1.0);
    }`
})
```

### 補足：Viteなどのビルドツールを使う場合

先ほど示したような、シェーダのコードをJavaScriptの文字列として埋め込む方法では、エディタのシンタックスハイライト機能の恩恵を受けられないですし、JavaScriptのコード全体が読みづらくなります。

シェーダのコードを別ファイルに分けて書きたい場合は、[Vite](https://ja.vite.dev/)などのビルドツールを使うと便利です。

たとえば、Viteでビルドする場合は、`shader.wgsl`という別ファイルに書いたシェーダのコードを、次のように`.js`（`.ts`）ファイルで`import{:js}`して使うことができます。

```ts title="Viteでビルドする場合の例"
// ?rawをつけることで、シェーダのコードを文字列としてimportできる
import shaderCode from "./shader.wgsl?raw"

const shaderModule = device.createShaderModule({
  code: shaderCode
})
```

### 発展：コンパイルエラーの検出

- コンパイルの結果は `compilationInfo()` で確認できる

```ts
// エラーチェック（非同期でバリデーション情報を取得）
shaderModule.compilationInfo().then((info) => {
  if (info.messages.length > 0) {
    for (const msg of info.messages) {
      console.warn(`${msg.lineNum}:${msg.linePos} - ${msg.message}`)
    }
    if (info.messages.some((m) => m.type === "error")) {
      throw new Error("シェーダのコンパイルに失敗しました")
    }
  }
})
```

## シェーダの使い方を伝える

シェーダを意図通りGPUに使ってもらうためには、GPUに対してさまざまな補足説明を伝える必要があります。

### レンダーパイプライン

WebGPUでは、==レンダーパイプライン==（`GPURenderPipeline{:ts}`）というオブジェクトに、シェーダの実行に関する設定を詰め込みます。

- どのシェーダーを使うか（頂点／フラグメント）
- 頂点データのレイアウトはどうなっているか
- 色をどう合成するか（ブレンド）
- 深度テストやカリングの方法
- 出力するフォーマット（カラーバッファの形式）
  etc.

言うなれば、レンダーパイプラインは=p=シェーダの調理法を詰め込んだレシピ==です。

### 補足：パイプラインという名前の解釈

グラフィックスAPIにおいて、==パイプライン==は「処理の流れ」のような意味を持つ言葉です。
たとえば、GPUのパイプラインは「頂点シェーダ→ラスタライズ→フラグメントシェーダ」という流れで処理を行います。

WebGPUにおける`GPURenderPipeline{:ts}`オブジェクトは、パイプラインの各処理工程に対して、それぞれ「どんな設定に基づいて処理してほしいか」をまとめて定義したものといえます。

その処理工程ではどういう「状態｣であってほしいか、WebGLではグローバルに散らばっていた状態を、WebGPUではレンダーパイプラインというオブジェクトに閉じ込めてしまうのです。設定をオブジェクト化することにより、その設定を使い回すことも容易になります。

## レンダーパイプラインの構成要素

レンダーパイプラインは、`device.createRenderPipeline(){:js}`メソッドで作成します。

このメソッドに引数として渡すオブジェクトは、さまざまな設定を詰め込んだものになります。

## 発展：パイプラインのレイアウト

## [DRAFT]

## 2. グラフィックスパイプラインの構成

WebGPUのパイプラインは大きく以下のような構成要素で作られます：

### a. シェーダーの設定

```ts
vertex: {
  module: shaderModule,
  entryPoint: "vs_main",
  buffers: [...]
},
fragment: {
  module: shaderModule,
  entryPoint: "fs_main",
  targets: [...]
}
```

- `shaderModule`：`device.createShaderModule()`で作ったWGSLコード
- `entryPoint`：シェーダー関数の名前（`@vertex`, `@fragment`）

### b. 入力レイアウト（`vertex.buffers`）

```ts
{
  arrayStride: 24,
  attributes: [
    { shaderLocation: 0, offset: 0, format: "float32x3" },
    { shaderLocation: 1, offset: 12, format: "float32x3" }
  ]
}
```

- 頂点バッファの構造（例：位置と法線が3つずつ）

### c. レンダーターゲット設定（`fragment.targets`）

```ts
{
  format: "bgra8unorm",
  blend: {
    color: {
      srcFactor: "src-alpha",
      dstFactor: "one-minus-src-alpha",
      operation: "add"
    },
    alpha: { ... }
  },
  writeMask: GPUColorWrite.ALL
}
```

- 書き込み先のテクスチャ形式やブレンドの方法

### d. 深度ステンシルの設定（任意）

```ts
depthStencil: {
  format: "depth24plus",
  depthWriteEnabled: true,
  depthCompare: "less"
}
```

### e. プリミティブの設定

```ts
primitive: {
  topology: "triangle-list",
  cullMode: "back",
  frontFace: "ccw"
}
```

### f. マルチサンプリング（任意）

```ts
multisample: {
  count: 4
}
```

## 3. パイプラインの使用方法

生成したパイプラインは、コマンドエンコーダーの中でこう使います：

```ts
renderPassEncoder.setPipeline(pipeline)
renderPassEncoder.draw(vertexCount)
```

これによって、GPUは「どう描画すべきか」のルールに従って描画を実行します。

## 4. 補足：バインドグループとの関係

パイプライン内では、リソース（バッファやテクスチャなど）をどう参照するか、という**バインドレイアウト**も決まっています。  
たとえば：

```ts
layout: "auto"
```

にすると、自動でバインドグループのレイアウトを推測してくれます。手動で指定も可能です（`device.createBindGroupLayout()`などを使って）。

---

## 実装：キャンバスに三角形を描画する

<DemoLinkWithResult
  url="/demo/webgpu-triangle-no-buffer"
  result={img_WebGpuTriangleNoBuffer}
  title="WebGPUで三角形を描画するデモ"
/>

```wgsl title="シェーダのコード" showLineNumbers
struct VertexInput {
  @builtin(vertex_index) VertexIndex: u32
};

struct VertexOutput {
  @builtin(position) Position: vec4f
};

@vertex
fn vs_main(in: VertexInput) -> VertexOutput {
  var pos = array<vec2f, 3>(
    vec2f( 0.0,  0.5),
    vec2f(-0.5, -0.5),
    vec2f( 0.5, -0.5)
  );

  var out: VertexOutput;
  out.Position = vec4f(pos[in.VertexIndex], 0.0, 1.0);
  return out;
}

@fragment
fn fs_main() -> @location(0) vec4f {
  return vec4f(0.918, 0.561, 0.918, 1.0);
}
```

```ts title="JavaScriptのコード" showLineNumbers {10-12,14-26,41-42}
const adapter = await navigator.gpu.requestAdapter()
const device = await adapter.requestDevice()

const canvas = document.querySelector("canvas")
const context = canvas.getContext("webgpu")

const canvasFormat = navigator.gpu.getPreferredCanvasFormat()
context.configure({ device, format: canvasFormat })

const shaderModule = device.createShaderModule({
  code: `(shader code)`
})

const renderPipeline = device.createRenderPipeline({
  layout: "auto",
  vertex: {
    module: shaderModule,
    entryPoint: "vs_main"
  },
  fragment: {
    module: shaderModule,
    entryPoint: "fs_main",
    targets: [{ format: canvasFormat }]
  },
  primitive: { topology: "triangle-list" }
})

const commandEncoder = device.createCommandEncoder()
const renderPassDescriptor = {
  colorAttachments: [
    {
      view: context.getCurrentTexture().createView(),
      loadOp: "clear",
      clearValue: { r: 0.32, g: 0.34, b: 0.36, a: 1 },
      storeOp: "store"
    }
  ]
}

const renderPass = commandEncoder.beginRenderPass(renderPassDescriptor)
renderPass.setPipeline(renderPipeline)
renderPass.draw(3)
renderPass.end()

device.queue.submit([encoder.finish()])
```
