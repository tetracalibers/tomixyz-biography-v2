---
title: シェーダを動かすパイプライン
date: "2025-04-20"
description: レンダーパイプラインで三角形を表示する
series: webgpu-concept
references:
  - title: WebGPU入門 - WebGPUで三角形を表示する
    url: https://zenn.dev/emadurandal/books/cb6818fd3a1b2e/viewer/hello_triangle
  - title: WebGPU Fundamentals
    url: https://webgpufundamentals.org/webgpu/lessons/webgpu-fundamentals.html
tags:
  - webgpu
draft: true
---

import DemoLinkWithResult from "$/components/demo/DemoLinkWithResult.astro"

import img_WebGpuTriangleNoBuffer from "../../../assets/recipes/webgpu-concept/webgpu-triangle-no-buffer.png"

> [!note]
> ここで学ぶこと
>
> - レンダーパイプライン
> - フラグメントシェーダ出力の`@location(0)`の意味

:SeriesPrevLink[前回]{series="webgpu-concept" current="webgpu-triangle-pipeline"}は、三角形の描画に必要なシェーダを実装しました。

今回は、そのシェーダを使って、実際に三角形を表示するためのWebGPUのコードを実装します。

## レンダーパイプライン

シェーダを意図通りGPUに使ってもらうためには、GPUに対してさまざまな補足説明を伝える必要があります。

WebGPUでは、==レンダーパイプライン==（`GPURenderPipeline{:ts}`）というオブジェクトに、シェーダの実行に関する設定を詰め込みます。

- どのシェーダーを使うか（頂点／フラグメント）
- 頂点データのレイアウトはどうなっているか
- 色をどう合成するか（ブレンド）
- 深度テストやカリングの方法
- 出力するフォーマット（カラーバッファの形式）
  etc.

グラフィックスAPIにおいて、==パイプライン==は「処理の流れ」のような意味を持つ言葉です。
たとえば、GPUのパイプラインは「頂点シェーダ→ラスタライズ→フラグメントシェーダ」という流れで処理を行います。
WebGPUにおける`GPURenderPipeline{:ts}`オブジェクトは、パイプラインの各処理工程に対して、それぞれ「どんな設定（状態）に基づいて処理してほしいか」をまとめて定義したものです。

## [DRAFT]

パイプラインとは、シェーダの調理法を詰め込んだレシピです。

この設定をあらかじめいくつも作り置きし、状況に応じてGPUにアタッチすることで、GPUのパイプライン状態を高速に変更することが可能となります。

---

## 1. パイプラインとは？
GPUに対して「どうやって描画するか？」を伝えるための**設計図**です。具体的には：

- どのシェーダーを使うか（頂点／フラグメント）
- 頂点データのレイアウトはどうなっているか
- 色をどう合成するか（ブレンド）
- 深度テストやカリングの方法
- 出力するフォーマット（カラーバッファの形式）など

すべてを一括で設定して、`device.createRenderPipeline()` でパイプラインを生成します。

## 2. グラフィックスパイプラインの構成

WebGPUのパイプラインは大きく以下のような構成要素で作られます：

### a. シェーダーの設定
```ts
vertex: {
  module: shaderModule,
  entryPoint: "vs_main",
  buffers: [...]
},
fragment: {
  module: shaderModule,
  entryPoint: "fs_main",
  targets: [...]
}
```
- `shaderModule`：`device.createShaderModule()`で作ったWGSLコード
- `entryPoint`：シェーダー関数の名前（`@vertex`, `@fragment`）

### b. 入力レイアウト（`vertex.buffers`）
```ts
{
  arrayStride: 24,
  attributes: [
    { shaderLocation: 0, offset: 0, format: "float32x3" },
    { shaderLocation: 1, offset: 12, format: "float32x3" }
  ]
}
```
- 頂点バッファの構造（例：位置と法線が3つずつ）

### c. レンダーターゲット設定（`fragment.targets`）
```ts
{
  format: "bgra8unorm",
  blend: {
    color: {
      srcFactor: "src-alpha",
      dstFactor: "one-minus-src-alpha",
      operation: "add"
    },
    alpha: { ... }
  },
  writeMask: GPUColorWrite.ALL
}
```
- 書き込み先のテクスチャ形式やブレンドの方法

### d. 深度ステンシルの設定（任意）
```ts
depthStencil: {
  format: "depth24plus",
  depthWriteEnabled: true,
  depthCompare: "less"
}
```

### e. プリミティブの設定
```ts
primitive: {
  topology: "triangle-list",
  cullMode: "back",
  frontFace: "ccw"
}
```

### f. マルチサンプリング（任意）
```ts
multisample: {
  count: 4
}
```

## 3. パイプラインの使用方法

生成したパイプラインは、コマンドエンコーダーの中でこう使います：

```ts
renderPassEncoder.setPipeline(pipeline);
renderPassEncoder.draw(vertexCount);
```

これによって、GPUは「どう描画すべきか」のルールに従って描画を実行します。

## 4. 補足：バインドグループとの関係
パイプライン内では、リソース（バッファやテクスチャなど）をどう参照するか、という**バインドレイアウト**も決まっています。  
たとえば：

```ts
layout: "auto"
```

にすると、自動でバインドグループのレイアウトを推測してくれます。手動で指定も可能です（`device.createBindGroupLayout()`などを使って）。

## まとめ
- パイプラインはGPU処理のレシピ（すべての設定の集合）
- シェーダー、バッファレイアウト、ブレンド、深度設定などが含まれる
- パイプラインは一度作って、使いまわすのが基本
- 描画系と計算系で種類が違う（Render vs Compute）

---

## 実装：キャンバスに三角形を描画する

<DemoLinkWithResult
  url="/demo/webgpu-triangle-no-buffer"
  result={img_WebGpuTriangleNoBuffer}
  title="WebGPUで三角形を描画するデモ"
/>

```wgsl title="シェーダのコード" showLineNumbers
struct VertexInput {
  @builtin(vertex_index) VertexIndex: u32
};

struct VertexOutput {
  @builtin(position) Position: vec4f
};

@vertex
fn vs_main(in: VertexInput) -> VertexOutput {
  var pos = array<vec2f, 3>(
    vec2f( 0.0,  0.5),
    vec2f(-0.5, -0.5),
    vec2f( 0.5, -0.5)
  );

  var out: VertexOutput;
  out.Position = vec4f(pos[in.VertexIndex], 0.0, 1.0);
  return out;
}

@fragment
fn fs_main() -> @location(0) vec4f {
  return vec4f(0.918, 0.561, 0.918, 1.0);
}
```

```ts title="JavaScriptのコード" showLineNumbers {10-12,14-26,41-42}
const adapter = await navigator.gpu.requestAdapter()
const device = await adapter.requestDevice()

const canvas = document.querySelector("canvas")
const context = canvas.getContext("webgpu")

const canvasFormat = navigator.gpu.getPreferredCanvasFormat()
context.configure({ device, format: canvasFormat })

const shaderModule = device.createShaderModule({
  code: `シェーダのコードをここに埋め込み`
})

const renderPipeline = device.createRenderPipeline({
  layout: "auto",
  vertex: {
    module: shaderModule,
    entryPoint: "vs_main"
  },
  fragment: {
    module: shaderModule,
    entryPoint: "fs_main",
    targets: [{ format: canvasFormat }]
  },
  primitive: { topology: "triangle-list" }
})

const commandEncoder = device.createCommandEncoder()
const renderPassDescriptor = {
  colorAttachments: [
    {
      view: context.getCurrentTexture().createView(),
      loadOp: "clear",
      clearValue: { r: 0.32, g: 0.34, b: 0.36, a: 1 },
      storeOp: "store"
    }
  ]
}

const renderPass = commandEncoder.beginRenderPass(renderPassDescriptor)
renderPass.setPipeline(renderPipeline)
renderPass.draw(3)
renderPass.end()

device.queue.submit([encoder.finish()])
```
